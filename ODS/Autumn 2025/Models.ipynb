{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d281d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd01cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a4977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите baseline модель lr_bankr_baseline\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "lr_bankr_baseline = LogisticRegression(random_state=RANDOM_STATE, solver='liblinear', class_weight='balanced')\n",
    "lr_bankr_baseline.fit(X_bankr_train, y_bankr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7fd280",
   "metadata": {},
   "outputs": [],
   "source": [
    "bankr_kbest_pipeline = Pipeline([\n",
    "    ('selector', SelectKBest(f_classif)),\n",
    "    ('clf', LogisticRegression(random_state=RANDOM_STATE, solver='liblinear', class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# С помощью GridSearchCV и bankr_kbest_pipeline подберите на обучающей выборке оптимальное количество признаков\n",
    "\n",
    "params = {\n",
    "    'selector__k': range(1, 40)\n",
    "}\n",
    "scoring = 'f1'\n",
    "cv = 5\n",
    "\n",
    "estimator = LogisticRegression(random_state=RANDOM_STATE, solver='liblinear', class_weight='balanced', penalty='l1')\n",
    "params = {'C' : [0.001, 0.005, 0.01, 0.05, 0.1, 0.5]}\n",
    "cv = 5\n",
    "scoring = 'f1'\n",
    "\n",
    "lr_diab = LogisticRegression(penalty=None, random_state=RANDOM_STATE).fit(X_diab_train, y_diab_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da806a",
   "metadata": {},
   "source": [
    "### **XGBoost, LightGBM и CatBoost**\n",
    "\n",
    "Среди существующих реализаций градиентного бустинга выделяются три наиболее эффективных и популярных алгоритма: XGBoost, LightGBM и CatBoost.\n",
    "\n",
    "* Extreme Gradient Boosting ([XGBoost](https://xgboost.readthedocs.io/en/latest/), DMLC 2014 г.) — эффективный и гибкий алгоритм градиентного бустинга с поддержкой регуляризации и параллельного обучения, обеспечивающий высокую производительность и универсальность. Алгоритм требует предварительной обработки категориальных признаков (например, One-Hot кодирование).\n",
    "\n",
    "* Light Gradient-Boosting Machine ([LightGBM](https://lightgbm.readthedocs.io/en/latest/), Microsoft 2016 г.) — алгоритм, который выделяется высокой скоростью обучения и масштабируемостью для больших объёмов данных и многомерных признаков. Алгоритм требует предварительной обработки категориальных признаков.\n",
    "\n",
    "\n",
    "* Category Boosting ([CatBoost](https://catboost.ai/), Яндекс 2017 г.) — алгоритм, который специализируется на эффективной работе с категориальными признаками и обладает устойчивостью к переобучению благодаря симметричной структуре деревьев. Алгоритм не требует предварительной обработки категориальных признаков — реализована автоматическая обработка категориальных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd4dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "estimator = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "params = {\n",
    "    'max_depth': range(1, 11),\n",
    "    'n_estimators': range(50, 300),\n",
    "    'learning_rate': np.linspace(0.05, 0.95, 100)\n",
    "}\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "estimator = XGBClassifier(random_state=RANDOM_STATE)\n",
    "params = {\n",
    "    'max_depth': range(1, 11),\n",
    "    'n_estimators': range(50, 300),\n",
    "    'learning_rate': np.linspace(0.05, 0.95, 100)\n",
    "}\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "estimator = LGBMClassifier(random_state=RANDOM_STATE, verbose=-1) # verbose=-1\n",
    "params = {\n",
    "    'max_depth': range(1, 11),\n",
    "    'n_estimators': range(50, 300),\n",
    "    'learning_rate': np.linspace(0.05, 0.95, 100)\n",
    "}\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "estimator = CatBoostClassifier(random_state=RANDOM_STATE, verbose=False, cat_features=empl_cat_feat)\n",
    "params = {\n",
    "    'max_depth': range(1, 11),\n",
    "    'n_estimators': range(50, 300),\n",
    "    'learning_rate': np.linspace(0.05, 0.95, 100)\n",
    "}\n",
    "\n",
    "# Обучите модель catb_stud c оптимальными гиперпараметрами\n",
    "# Для обучения и валидации используйте sample_train и sample_val\n",
    "\n",
    "catb_stud_params = {\n",
    "    'cat_features': stud_cat_feat,\n",
    "    'eval_metric': 'Accuracy',\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "catb_stud = CatBoostClassifier(**catb_stud_params, **stud_study.best_params).fit(\n",
    "    X_stud_sample_train, \n",
    "    y_stud_sample_train,\n",
    "    eval_set=(X_stud_sample_val, y_stud_sample_val)\n",
    "    # optional early_stopping_rounds=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89aff8e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497822fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "\n",
    "if_fraud = IsolationForest(n_estimators=500, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ddbc66",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53d7e947",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d723d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_retail = DecisionTreeRegressor(\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=RANDOM_STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf4c204",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_tree = DecisionTreeClassifier(max_depth=3, random_state=RANDOM_STATE)\n",
    "sklearn_tree.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628edf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "params = {\n",
    "    'max_depth': range(5, 15),\n",
    "    'min_samples_split': range(2, 10),\n",
    "    'min_samples_leaf': range(2, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea963c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier(n_estimators=5, random_state=RANDOM_STATE)\n",
    "\n",
    "params = {\n",
    "    'n_estimators': range(5, 200),\n",
    "    'min_samples_split': range(2, 10),\n",
    "    'min_samples_leaf': range(2, 10),\n",
    "}\n",
    "n_iter = 50\n",
    "scoring = 'roc_auc'\n",
    "cv = 5\n",
    "\n",
    "params = {\n",
    "    'max_depth': range(1, 11),\n",
    "    'n_estimators': range(50, 300)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
