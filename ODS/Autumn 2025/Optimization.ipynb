{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcea1498",
   "metadata": {},
   "source": [
    "[RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) — метод подбора оптимальных гиперпараметров модели, суть которого состоит в переборе случайных комбинаций значений параметров из заданных диапазонов или распределений вместо полного перебора всех возможных комбинаций (как это реализовано в GridSearchCV).\n",
    "\n",
    "**RandomizedSearchCV и GridSearchCV**:\n",
    "\n",
    "* **RandomizedSearchCV** выбирает комбинации случайно. Это снижает вычислительные затраты и позволяет находить приемлемые (иногда лучшие) гиперпараметры при меньших вычислительных затратах. **Параметр n_iter** указывает число случайных комбинаций гиперпараметров, которые будут протестированы в процессе подбора.\n",
    "\n",
    "* **GridSearchCV** перебирает все комбинации значений гиперпараметров. Это гарантирует нахождение результата внутри сетки, но требует много времени, особенно при большом числе параметров или возможных значений.\n",
    "\n",
    "Подробнее можно изучить по **ссылке:**\n",
    "\n",
    "* [Рандомизированная оптимизация параметров | scikit-learn.ru](https://scikit-learn.ru/stable/modules/grid_search.html#randomized-parameter-search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a480bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_iter = 50\n",
    "scoring = 'roc_auc'\n",
    "cv = 5\n",
    "\n",
    "cv_ran = RandomizedSearchCV(\n",
    "    estimator=model(random_state=RANDOM_STATE),\n",
    "    param_distributions=params,\n",
    "    n_iter=n_iter,\n",
    "    scoring=scoring,\n",
    "    cv=cv,\n",
    "    random_state=RANDOM_STATE\n",
    "    n_jobs=-1, # Может ускорить вычисления за счёт параллелизма, не влияет на результат\n",
    "    refit=True # Переобучает модель на всей выборке после подбора гиперпараметров (по умолчанию True, можно не указывать)\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "cv_best = cv_ran.best_estimator_\n",
    "\n",
    "# Выведите оптимальные гиперпараметры обучения tree_titanic и номер итерации, на котором они были достигнуты\n",
    "\n",
    "print(f'Оптимальные параметры DecisionTreeClassifier на итерации {cv_ran.best_index_}: {cv_ran.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b324f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b685d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [100, 150, 200, 250],\n",
    "    'learning_rate': [0.1, 0.2, 0.3, 0.4],\n",
    "    'max_depth': [1, 2, 3]\n",
    "}\n",
    "cv = 5\n",
    "\n",
    "cv_grid = GridSearchCV(\n",
    "    estimator=model(random_state=RANDOM_STATE),\n",
    "    param_grid=params,\n",
    "    cv=cv,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "cv_grid.fit(X, y)\n",
    "\n",
    "# Выведите оптимальные гиперпараметры по результатам оптимизации\n",
    "\n",
    "print(f'Оптимальные параметры: {cv_grid.best_params_}')\n",
    "print(f'Лучший score: {cv_grid.best_score_:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d104ac4",
   "metadata": {},
   "source": [
    "### **Early Stopping**\n",
    "\n",
    "Ранняя остановка (Early Stopping) — это универсальный и широко распространённый метод регуляризации, который позволяет эффективно предотвращать переобучение моделей. Суть метода заключается в остановке обучения модели до завершения всех запланированных итераций в случае, если прогнозные способности модели на валидационной выборке перестают улучшаться или начинают ухудшаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd22ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c907c03a",
   "metadata": {},
   "source": [
    "### **Вероятностные методы оптимизации гиперпараметров**\n",
    "\n",
    "Вероятностные методы оптимизации гиперпараметров — это итерационные методы, которые позволяют находить оптимальные гиперпараметры обучения моделей быстрее и точнее, чем Grid Search и Randomized Search, за счет использования вероятностной модели целевой функции. \n",
    "\n",
    "На каждой итерации метод оценивает, в какой следующей точке с наибольшей вероятностью будет достигнуто улучшение текущей оценки оптимума. Вероятностные методы особенно полезны при работе со сложными многомерными пространствами гиперпараметров.\n",
    "\n",
    "**Преимущества вероятностных методов перед Grid Search и Randomized Search:**\n",
    "\n",
    "* Каждая итерация использует информацию, полученную на предыдущих итерациях.\n",
    "\n",
    "* Вероятностные методы способны моделировать внутренние зависимости между гиперпараметрами.\n",
    "\n",
    "* Вероятностные методы позволяют достичь более высокого качества, если было выполнено достаточное количество итераций.\n",
    "\n",
    "* Гибкость. Вероятностные методы способны работать с непрерывными, дискретными и категориальными параметрами.\n",
    "\n",
    "**Основным недостатком** вероятностных методов является высокая вычислительная сложность по сравнению с Grid Search и Randomized Search.\n",
    "\n",
    "Одним из основных вероятностных методов является TPE (Tree-structured Parzen Estimator). TPE реализован в двух наиболее популярных библиотеках для оптимизации гиперпараметров: Optuna и Hyperopt.\n",
    "\n",
    "Подробнее можно изучить по **ссылкам:**\n",
    "\n",
    "* [Подбор гиперпараметров | education.yandex.ru](https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov).\n",
    "\n",
    "* [Optuna vs Hyperopt: Which Hyperparameter Optimization Library Should You Choose? | eptun.ai](https://neptune.ai/blog/optuna-vs-hyperopt)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f38fbeb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
