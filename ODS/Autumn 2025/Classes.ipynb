{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6b9f20b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f947e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополните класс CustomDecisionTreeClassifier\n",
    "# Код методов plot_node, plot_tree и count_nodes изменять не нужно\n",
    "\n",
    "class CustomDecisionTreeClassifier():\n",
    "    \"\"\"\n",
    "    Простой классификатор на основе дерева решений с критерием Джини в качестве критерия разделения.\n",
    "\n",
    "    Аргументы:frrrrrrrrrrrrr\n",
    "        max_depth (int): Максимальная глубина дерева. По умолчанию — 3.\n",
    "\n",
    "    Атрибуты:\n",
    "        label (int): Метка класса, который наиболее часто встречается в узле.\n",
    "        feature (str): Признак, используемый для разделения.\n",
    "        size (int): Количество объектов в узле.\n",
    "        threshold (float): Пороговое значение для разделения.\n",
    "        left (CustomDecisionTreeClassifier): Левое поддерево (значение <= порог).\n",
    "        right (CustomDecisionTreeClassifier): Правое поддерево (значение > порог).\n",
    "        gini (float): Индекс Джини в узле.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth=3):\n",
    "        self.max_depth = max_depth\n",
    "        self.label = None\n",
    "        self.feature = None\n",
    "        self.size = None\n",
    "        self.threshold = np.nan\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.gini = 0\n",
    "\n",
    "    def gini_impurity(self, y):\n",
    "        \"\"\"\n",
    "        Вычисляет индекс Джини для массива меток классов.\n",
    "\n",
    "        Аргументы:\n",
    "            y (numpy.ndarray): Массив меток классов.\n",
    "\n",
    "        Возвращает:\n",
    "            float: Значение индекса Джини.\n",
    "        \"\"\"\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        return 1 - np.sum(probabilities ** 2)\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        \"\"\"\n",
    "        Находит оптимальный признак и порог для разделения данных.\n",
    "\n",
    "        Аргументы:\n",
    "            X (pandas.DataFrame): Таблица с признаками.\n",
    "            y (numpy.ndarray): Массив меток классов.\n",
    "\n",
    "        Возвращает:\n",
    "            tuple:\n",
    "                str: Оптимальный признак для разделения.\n",
    "                float: Оптимальное пороговое значение.\n",
    "                float: Значение индекса Джини после оптимального разделения.\n",
    "        \"\"\"\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_gini = self.gini_impurity(y)\n",
    "        N = X.shape[0]\n",
    "        for feature in X.columns:\n",
    "            values = np.sort(X[feature].unique())\n",
    "            thresholds = [(values[i] + values[i+1]) / 2 for i in range(len(values)-1)]\n",
    "            for threshold in thresholds:\n",
    "                mask_left = X[feature] <= threshold\n",
    "                mask_right = ~mask_left\n",
    "                N_left = mask_left.sum() \n",
    "                N_right = mask_right.sum()\n",
    "                if N_left == 0 or N_right == 0:\n",
    "                    continue  \n",
    "                gini_left = self.gini_impurity(y[mask_left])\n",
    "                gini_right = self.gini_impurity(y[mask_right])\n",
    "                weighted_gini = (N_left * gini_left + N_right * gini_right) / N\n",
    "                if weighted_gini < best_gini:\n",
    "                    best_gini = weighted_gini\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold, best_gini\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучает дерево решений, рекурсивно находя оптимальные разделения.\n",
    "\n",
    "        Аргументы:\n",
    "            X (pandas.DataFrame): Таблица с признаками.\n",
    "            y (numpy.ndarray): Массив меток классов.\n",
    "\n",
    "        Возвращает:\n",
    "            CustomDecisionTreeClassifier: Обученное дерево решений.\n",
    "        \"\"\"\n",
    "        self.size = len(y)\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        self.label = classes[np.argmax(counts)]\n",
    "        self.gini = self.gini_impurity(y)\n",
    "        if self.max_depth == 0:\n",
    "            return \n",
    "        self.feature, self.threshold, gini = self.best_split(X, y)\n",
    "        if self.feature is None or gini >= self.gini:\n",
    "            return\n",
    "        self.gini = gini\n",
    "        mask_left = X[self.feature] <= self.threshold\n",
    "        mask_right = ~mask_left\n",
    "        self.left = CustomDecisionTreeClassifier(max_depth=self.max_depth-1)\n",
    "        self.right = CustomDecisionTreeClassifier(max_depth=self.max_depth-1)\n",
    "        self.left.fit(X[mask_left], y[mask_left])\n",
    "        self.right.fit(X[mask_right], y[mask_right])\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказывает метки классов.\n",
    "\n",
    "        Аргументы:\n",
    "            X (pandas.DataFrame): Таблица с признаками.\n",
    "\n",
    "        Возвращает:\n",
    "            numpy.ndarray: Массив предсказанных меток классов.\n",
    "        \"\"\"\n",
    "        if self.feature is None:\n",
    "            return np.full(X.shape[0], self.label)  \n",
    "        mask_left = X[self.feature] <= self.threshold\n",
    "        mask_right = ~mask_left\n",
    "        y_pred = np.empty(X.shape[0])\n",
    "        y_pred[mask_left] = self.left.predict(X[mask_left])\n",
    "        y_pred[mask_right] = self.right.predict(X[mask_right])\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "    def plot_node(self, dot, node_id=0):\n",
    "        \"\"\"\n",
    "        Вспомогательный метод для визуализации дерева.\n",
    "\n",
    "        Аргументы:\n",
    "            dot (graphviz.Digraph): Объект Digraph библиотеки graphviz.\n",
    "            node_id (int): Идентификатор текущего узла. По умолчанию — 0.\n",
    "\n",
    "        Возвращает:\n",
    "            int: Идентификатор узла.\n",
    "        \"\"\"\n",
    "        if self.feature is None:\n",
    "            label = f\"gini = {self.gini:.3f}\\nsamples = {self.size}\\nlabel = {self.label}\"\n",
    "            dot.node(str(node_id), label=label, fillcolor=\"#8ccd96\")\n",
    "            return node_id\n",
    "        label = f\"{self.feature} <= {self.threshold:.3f}\\ngini = {self.gini:.3f}\\nsamples = {self.size}\\nlabel = {self.label}\"\n",
    "        dot.node(str(node_id), label=label, fillcolor=\"#ffffff\")\n",
    "        left_id = self.left.plot_node(dot, node_id*2 + 1)\n",
    "        dot.edge(str(node_id), str(left_id))\n",
    "        right_id = self.right.plot_node(dot, node_id*2 + 2)\n",
    "        dot.edge(str(node_id), str(right_id))\n",
    "        \n",
    "        return node_id\n",
    "\n",
    "    def plot_tree(self, filled=True):\n",
    "        \"\"\"\n",
    "        Генерирует визуализацию дерева решений.\n",
    "\n",
    "        Аргументы:\n",
    "            filled (bool): Закрашивать узлы. По умолчанию — True.\n",
    "\n",
    "        Возвращает:\n",
    "            graphviz.Digraph: Объект graphviz с визуализацией дерева.\n",
    "        \"\"\"\n",
    "        dot = graphviz.Digraph()\n",
    "        dot.attr('node', shape='box', style='filled' if filled else None)\n",
    "        self.plot_node(dot)\n",
    "        return dot\n",
    "    \n",
    "    def count_nodes(self):\n",
    "        \"\"\"\n",
    "        Рассчитывает сложность дерева — совокупное количество узлов в дереве.\n",
    "\n",
    "        Возвращает:\n",
    "            int: Общее количество узлов.\n",
    "        \"\"\"\n",
    "        if self.feature is None:\n",
    "            return 1\n",
    "        return 1 + self.left.count_nodes() + self.right.count_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee3527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополните класс CustomDecisionTreeRegressor\n",
    "# Код методов plot_node, plot_tree и count_nodes изменять не нужно\n",
    "\n",
    "class CustomDecisionTreeRegressor():\n",
    "    \"\"\"\n",
    "    Простой регрессор на основе дерева решений с ошибкой MSE в качестве критерия разделения и средним значением в листе для прогноза.\n",
    "\n",
    "    Аргументы:\n",
    "        max_depth (int): Максимальная глубина дерева. По умолчанию — 8.\n",
    "\n",
    "    Атрибуты:\n",
    "        value (float): Среднее значение целевой переменной в узле.\n",
    "        feature (str): Признак, используемый для разделения.\n",
    "        size (int): Количество объектов в узле.\n",
    "        threshold (float): Пороговое значение для разделения.\n",
    "        left (CustomDecisionTreeRegressor): Левое поддерево (значение <= порог).\n",
    "        right (CustomDecisionTreeRegressor): Правое поддерево (значение > порог).\n",
    "        mse (float): Ошибка MSE в узле.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth=8):\n",
    "        self.max_depth = max_depth\n",
    "        self.value = None\n",
    "        self.feature = None\n",
    "        self.size = None\n",
    "        self.threshold = np.nan\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.mse = 0\n",
    "\n",
    "\n",
    "    def MSE(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Вычисляет среднеквадратичную ошибку (MSE).\n",
    "\n",
    "        Аргументы:\n",
    "            y_true (numpy.ndarray): Массив истинных значений целевой переменной.\n",
    "            y_pred (numpy.ndarray): Массив предсказанных значений целевой переменной.\n",
    "\n",
    "        Возвращает:\n",
    "            float: Значение MSE.\n",
    "        \"\"\"\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        \"\"\"\n",
    "        Находит оптимальный признак и порог для разделения данных.\n",
    "\n",
    "        Аргументы:\n",
    "            X (pandas.DataFrame): Таблица с признаками.\n",
    "            y (numpy.ndarray): Массив значений целевой переменной.\n",
    "\n",
    "        Возвращает:\n",
    "            tuple:\n",
    "                str: Оптимальный признак для разделения.\n",
    "                float: Оптимальное пороговое значение.\n",
    "                float: Значение среднеквадратичной ошибки (MSE) после разделения.\n",
    "        \"\"\"\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_mse = self.MSE(y, y.mean())\n",
    "        N = X.shape[0]\n",
    "        for feature in X.columns:\n",
    "            values = np.sort(X[feature].unique())\n",
    "            thresholds = [(values[i] + values[i+1]) / 2 for i in range(len(values) - 1)]\n",
    "            for threshold in thresholds:\n",
    "                mask_left = X[feature] <= threshold\n",
    "                mask_right = ~mask_left\n",
    "                N_left = mask_left.sum()\n",
    "                N_right = mask_right.sum()\n",
    "                if N_left == 0 or N_right == 0:\n",
    "                    continue\n",
    "                loss_left = self.MSE(y[mask_left], y[mask_left].mean())\n",
    "                loss_right = self.MSE(y[mask_right], y[mask_right].mean())\n",
    "                weighted_mse = (N_left * loss_left + N_right * loss_right) / N\n",
    "                if weighted_mse < best_mse:\n",
    "                    best_mse = weighted_mse\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        return best_feature, best_threshold, best_mse\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучает дерево решений, рекурсивно находя оптимальные разделения.\n",
    "\n",
    "        Аргументы:\n",
    "            X (pandas.DataFrame): Таблица с признаками.\n",
    "            y (numpy.ndarray): Массив значений целевой переменной.\n",
    "\n",
    "        Возвращает:\n",
    "            CustomDecisionTreeRegressor: Обученное дерево решений.\n",
    "        \"\"\"\n",
    "        self.value = y.mean()\n",
    "        self.mse = self.MSE(y, self.value)\n",
    "        self.size = len(y)\n",
    "        if self.max_depth == 0:\n",
    "            return\n",
    "        self.feature, self.threshold, mse = self.best_split(X, y)\n",
    "        if self.feature is None or mse >= self.mse:\n",
    "            return\n",
    "        self.mse = mse\n",
    "        mask_left = X[self.feature] <= self.threshold\n",
    "        mask_right = ~mask_left\n",
    "        self.left = CustomDecisionTreeRegressor(max_depth=self.max_depth-1)\n",
    "        self.right = CustomDecisionTreeRegressor(max_depth=self.max_depth-1)\n",
    "        self.left.fit(X[mask_left], y[mask_left])\n",
    "        self.right.fit(X[mask_right], y[mask_right])\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказывает значения целевой переменной.\n",
    "\n",
    "        Аргументы:\n",
    "            X (pandas.DataFrame): Таблица с признаками.\n",
    "\n",
    "        Возвращает:\n",
    "            numpy.ndarray: Массив предсказанных значений целевой переменной.\n",
    "        \"\"\"\n",
    "        if self.feature is None:\n",
    "            return np.full(X.shape[0], self.value)\n",
    "        mask_left = X[self.feature] <= self.threshold\n",
    "        mask_right = ~mask_left\n",
    "        y_pred = np.empty(X.shape[0])\n",
    "        y_pred[mask_left] = self.left.predict(X[mask_left])\n",
    "        y_pred[mask_right] = self.right.predict(X[mask_right])\n",
    "        return y_pred\n",
    "    \n",
    "    def prune(self, epsilon):\n",
    "        \"\"\"\n",
    "        Обрезает дерево, если разница ошибок между родительским и дочерними узлами меньше epsilon.\n",
    "        После обрезки внутренний узел становится листом.\n",
    "\n",
    "        Аргументы:\n",
    "            epsilon (float): Пороговое значение для обрезки.\n",
    "        \"\"\"\n",
    "        if self.feature is None:\n",
    "            return\n",
    "        self.left.prune(epsilon)\n",
    "        self.right.prune(epsilon)\n",
    "        left_size = self.left.size\n",
    "        right_size = self.right.size\n",
    "        left_mse = self.left.mse\n",
    "        right_mse = self.right.mse\n",
    "        weighted_mse = (left_size * left_mse + right_size * right_mse) / (left_size + right_size)\n",
    "        if weighted_mse > 0 and (self.mse - weighted_mse) < epsilon:\n",
    "            self.feature = None\n",
    "            self.threshold = np.nan\n",
    "            self.left = None\n",
    "            self.right = None\n",
    "    \n",
    "    def plot_node(self, dot, node_id=0):\n",
    "        \"\"\"\n",
    "        Вспомогательный метод для визуализации дерева.\n",
    "\n",
    "        Аргументы:\n",
    "            dot (graphviz.Digraph): Объект Digraph библиотеки graphviz.\n",
    "            node_id (int): Идентификатор текущего узла. По умолчанию — 0.\n",
    "\n",
    "        Возвращает:\n",
    "            int: Идентификатор узла.\n",
    "        \"\"\"\n",
    "        if self.feature == None:\n",
    "            dot.node(str(node_id), label='mse = {:.3f}\\nsamples = {}\\nvalue = {:.3f}'.format(self.mse, self.size, self.value), fillcolor=\"#8ccd96\")\n",
    "            return node_id\n",
    "        dot.node(str(node_id), label='{} <= {:.3f}\\nmse = {:.3f}\\nsamples = {}\\nvalue = {:.3f}'\n",
    "                 .format(self.feature, self.threshold, self.mse, self.size, self.value), fillcolor=\"#ffffff\")\n",
    "        left_id = self.left.plot_node(dot, node_id*2 + 1)\n",
    "        dot.edge(str(node_id), str(left_id))\n",
    "        right_id = self.right.plot_node(dot, node_id*2 + 2)\n",
    "        dot.edge(str(node_id), str(right_id))\n",
    "        return node_id\n",
    "    \n",
    "    def plot_tree(self, filled=True):\n",
    "        \"\"\"\n",
    "        Генерирует визуализацию дерева решений.\n",
    "\n",
    "        Аргументы:\n",
    "            filled (bool): Закрашивать узлы. По умолчанию — True.\n",
    "\n",
    "        Возвращает:\n",
    "            graphviz.Digraph: Объект graphviz с визуализацией дерева.\n",
    "        \"\"\"\n",
    "        dot = graphviz.Digraph()\n",
    "        dot.attr('node', shape='box', style='filled' if filled else None)\n",
    "        self.plot_node(dot)\n",
    "        return dot\n",
    "    \n",
    "    def count_nodes(self):\n",
    "        \"\"\"\n",
    "        Рассчитывает сложность дерева — совокупное количество узлов в дереве.\n",
    "\n",
    "        Возвращает:\n",
    "            int: Общее количество узлов.\n",
    "        \"\"\"\n",
    "        if self.feature is None:\n",
    "            return 1\n",
    "        return 1 + self.left.count_nodes() + self.right.count_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe761b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# класс CustomGradientBoostingRegressor\n",
    "\n",
    "\n",
    "class CustomGradientBoostingRegressor(BaseEstimator):\n",
    "    \"\"\"\n",
    "    Простой регрессор на основе градиентного бустинга над деревьями решений.\n",
    "\n",
    "    Аргументы:\n",
    "        n_estimators (int): Количество деревьев (итераций бустинга). По умолчанию — 100.\n",
    "        learning_rate (float) Темп обучения (шаг градиентного спуска). По умолчанию — 0.1.\n",
    "        max_depth (int): Максимальная глубина дерева бустинга. По умолчанию — 1.\n",
    "        random_state : (int|None): Сид для фиксирования случайного состояния. По умолчанию — None (не фиксировать).\n",
    "\n",
    "    Атрибуты:\n",
    "        f0 (float): Начальное предсказание (среднее значение целевой переменной).\n",
    "        models (list[DecisionTreeRegressor]): Последовательность деревьев, составляющих модель градиентного бустинга.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=1, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        self.f0 = None\n",
    "        self.models = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучает модель градиентного бустинга.\n",
    "\n",
    "        Аргументы:\n",
    "            X (pandas.DataFrame): Таблица с признаками.\n",
    "            y (numpy.ndarray): Массив значений целевой переменной.\n",
    "\n",
    "        Возвращает: \n",
    "            CustomGradientBoostingRegressor: Обученная модель градиентного бустинга.\n",
    "        \"\"\"\n",
    "        self.f0 = np.mean(y)\n",
    "        y_pred = np.full_like(y, self.f0)\n",
    "        for _ in range(self.n_estimators):\n",
    "            residuals = y - y_pred\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth, random_state=self.random_state)\n",
    "            tree.fit(X, residuals)\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "            self.models.append(tree)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказывает значения целевой переменной.\n",
    "\n",
    "        Аргументы:\n",
    "            X (pandas.DataFrame): Таблица с признаками.\n",
    "\n",
    "        Возвращает:\n",
    "            numpy.ndarray: Массив предсказанных значений целевой переменной.\n",
    "        \"\"\"\n",
    "        y_pred = np.full(X.shape[0], self.f0)\n",
    "        for model in self.models:\n",
    "            y_pred += self.learning_rate * model.predict(X)\n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Вычисляет отрицательное значение MSE (Negative MSE) для прогноза.\n",
    "        Метод необходим для применения GridSearchCV.\n",
    "\n",
    "        Аргументы:\n",
    "            X (pandas.DataFrame): Таблица с признаками.\n",
    "            y (numpy.ndarray): Массив значений целевой переменной.\n",
    "\n",
    "        Возвращает:\n",
    "            float: Значение Negative MSE.\n",
    "        \"\"\"\n",
    "        return -mean_squared_error(y, self.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26afd4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e922e57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
