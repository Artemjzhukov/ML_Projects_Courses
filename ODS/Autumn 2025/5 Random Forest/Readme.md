## датасет [Titanic Dataset](https://www.kaggle.com/datasets/yasserh/titanic-dataset)

# Аналитический отчет по проекту "Деревья решений и случайные леса"

## Описание задачи и методов

Проект посвящен сравнительному анализу алгоритмов деревьев решений и случайных лесов для задач бинарной классификации. Исследование проводилось на двух наборах данных: синтетическом датасете make_circles с нелинейно разделимыми классами и реальных данных Titanic о выживаемости пассажиров. Основной фокус работы - оценка влияния гиперпараметров на качество моделей и сравнение эффективности одиночных деревьев с ансамблевыми методами.

Для деревьев решений исследовались параметры максимальной глубины (max_depth в диапазоне 5-14), минимального числа samples для разделения (min_samples_split 2-9) и минимального числа samples в листе (min_samples_leaf 2-9). Для случайных лесов дополнительно анализировалось количество деревьев в ансамбле (n_estimators 5-199). Оптимизация гиперпараметров выполнялась с помощью RandomizedSearchCV с 50 итерациями и 5-кратной кросс-валидацией, целевой метрикой выбран AUC-ROC.

## Результаты экспериментов

На синтетических данных circles дерево решений достигло accuracy 0.8125, в то время как случайный лес из 5 деревьев показал accuracy 0.8400. Разница в качестве составила 0.0275. Модель случайного леса продемонстрировала сбалансированное качество предсказаний для обоих классов: precision класса 0 составил 0.8434, класса 1 - 0.8366, разница менее 0.0068.

На реальных данных Titanic оптимизированное дерево решений достигло AUC 0.8402 и accuracy 0.8039. Случайный лес из 5 деревьев показал AUC 0.8345 и accuracy 0.7927. После оптимизации гиперпараметров случайный лес достиг AUC 0.8606 и accuracy 0.8347, что представляет улучшение на 0.0204 по AUC и 0.0308 по accuracy относительно одиночного дерева.

Оптимальные параметры для дерева на данных Titanic: max_depth=5, min_samples_split=9, min_samples_leaf=8. Для случайного леса оптимальное количество деревьев составило 58 при min_samples_split=4 и min_samples_leaf=4.

## Анализ эффективности методов

Деревья решений продемонстрировали склонность к созданию сложных границ решений, что особенно заметно на синтетических данных, где модель пыталась точно аппроксимировать нелинейную границу между классами. Это приводит к повышенному риску переобучения, что подтверждается выбором ограниченной глубины 5 в оптимальной конфигурации.

Случайные леса показали более стабильные результаты за счет механизма бэггинга и случайного выбора признаков. Увеличение количества деревьев в ансамбле до 58 привело к значительному улучшению качества, при этом дальнейший рост числа деревьев сверх этого значения, согласно результатам оптимизации, не дает существенного выигрыша.

Метрика AUC продемонстрировала лучшую чувствительность к различиям в качестве моделей по сравнению с accuracy. Разница в AUC между оптимизированным случайным лесом и деревом составила 0.0204, в то время как разница в accuracy - 0.0308.

## Выводы о применимости подходов

Деревья решений эффективны для начального анализа данных и построения интерпретируемых моделей, особенно при ограниченных вычислительных ресурсах. Ограничение глубины дерева до 5 уровней на данных Titanic позволило сохранить баланс между качеством и сложностью модели.

Случайные леса демонстрируют превосходство в задачах, где важна устойчивость прогноза и обобщающая способность. Оптимальное количество деревьев в ансамбле зависит от конкретной задачи и объема данных, в данном исследовании наилучшие результаты достигнуты при 58 деревьях.

Оба метода требуют тщательного подбора гиперпараметров для достижения максимальной эффективности. Использование автоматизированных методов оптимизации, таких как RandomizedSearchCV, позволяет систематически находить близкие к оптимальным комбинации параметров без полного перебора всех возможных вариантов.

Для практического применения рекомендуется начинать с деревьев решений для понимания структуры данных и значимости признаков, затем переходить к случайным лесам для улучшения прогнозной точности. Критически важным является использование кросс-валидации для надежной оценки качества моделей и предотвращения переобучения.
